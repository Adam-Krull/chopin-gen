{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chopin_gen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXi7Iyx3K1do"
      },
      "source": [
        "import music21"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRG6CHD1K-jX"
      },
      "source": [
        "from music21 import converter, instrument, note, chord\n",
        "\n",
        "def read_midi(file):\n",
        "\n",
        "  notes = []\n",
        "  notes_to_parse = None\n",
        "\n",
        "  midi = converter.parse(file)\n",
        "\n",
        "  s2 = instrument.partitionByInstrument(midi)\n",
        "\n",
        "  for part in s2.parts:\n",
        "\n",
        "    if \"Piano\" in str(part):\n",
        "\n",
        "      notes_to_parse = part.recurse()\n",
        "\n",
        "      for element in notes_to_parse:\n",
        "\n",
        "        if isinstance(element, note.Note):\n",
        "          notes.append(str(element.pitch))\n",
        "\n",
        "        elif isinstance(element, chord.Chord):\n",
        "          notes.append(\".\".join(str(n) for n in element.normalOrder))\n",
        "\n",
        "  return np.array(notes)            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jWSj8MINBTT"
      },
      "source": [
        "Defines the function that will be used to read in the notes and chords from the MIDI music files. It creates some empty “container” variables and parses the MIDI file, iterating through the different parts and acting only on the piano music. The function iterates through each element in the piano part, adding each note to the list of notes. If the function encounters a chord, it breaks the chord down into individual notes and adds them to the list. A numpy array of the notes list is returned at the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEH21yPZNrJV"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "path = \"/content/\"\n",
        "\n",
        "files = [i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
        "\n",
        "notes_array = np.array([read_midi(path + i) for i in files])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kuS48bmNDir"
      },
      "source": [
        "Creates a list of all appropriate files in the path (MIDI music files). It iterates over the list of files, applying our MIDI reading function to each file and wrapping the results in a numpy array. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBAqqVWARaLn"
      },
      "source": [
        "notes_ = [element for note_ in notes_array for element in note_]\n",
        "\n",
        "unique_notes = list(set(notes_))\n",
        "print(len(unique_notes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uovzQ6MaR3CU"
      },
      "source": [
        "from collections import Counter\n",
        "freq = dict(Counter(notes_))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "no = [count for _, count in freq.items()]\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "plt.hist(no)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbgWDGibTVNE"
      },
      "source": [
        "frequent_notes = [note_ for note_, count in freq.items() if count>= 50]\n",
        "print(len(frequent_notes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYr8IUMcNNQQ"
      },
      "source": [
        "Helps us understand the data we have processed. The third cell creates a list of all notes found in the dataset, creates a set of unique notes, and prints the number of unique notes found in the music. Note that the term “unique notes” includes chords in this example, because the program found 316 unique “notes” and a full-size piano has 88 keys. The fourth cell counts the frequency of each note/chord in the dataset and creates a dictionary from the results. It iterates through the items of the dictionary and creates a list of the frequencies. These frequencies are plotted in a histogram. The histogram shows a small portion of the notes are repeated with a high frequency. The fifth cell decides to focus on these frequent notes, creating a new list of notes if they occur over 50 times in the music. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt5IOVnCUElt"
      },
      "source": [
        "new_music = []\n",
        "\n",
        "for notes in notes_array:\n",
        "  temp = []\n",
        "  for note_ in notes:\n",
        "    if note_ in frequent_notes:\n",
        "      temp.append(note_)\n",
        "  new_music.append(temp)\n",
        "\n",
        "new_music = np.array(new_music)      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0T5yS9kNSEf"
      },
      "source": [
        "Creates a new, concise dataset to be used for the rest of the program, because it contains only the most frequent notes/chords from the original dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN_fpaPlUvXg"
      },
      "source": [
        "timesteps = 32\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for note_ in new_music:\n",
        "  for i in range(0, len(note_) - timesteps, 1):\n",
        "\n",
        "    input_ = note_[i : i + timesteps]\n",
        "    output_ = note_[i + timesteps]\n",
        "\n",
        "    x.append(input_)\n",
        "    y.append(output_)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjxresndNWMP"
      },
      "source": [
        "Treats the music as a time series, defining the window as 32 notes and the answer as the 33rd. It iterates over the new dataset using this window and saves these slices to x (the 32 notes) and y (the 33rd note) numpy arrays. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXZ04uL6XnL5"
      },
      "source": [
        "unique_x = list(set(x.ravel()))\n",
        "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wOGRqfwNbpp"
      },
      "source": [
        "Creates a set from the flattened x array. It uses this set to assign a unique number to each note found in the x array. The assigned number is pulled from the enumerate function called in the second row of the cell. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67hSykDaU-RC"
      },
      "source": [
        "x_seq = []\n",
        "\n",
        "for i in x:\n",
        "  temp = []\n",
        "  for j in i:\n",
        "    temp.append(x_note_to_int[j])\n",
        "  x_seq.append(temp)\n",
        "\n",
        "x_seq = np.array(x_seq)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGKcN_rjNfSr"
      },
      "source": [
        "Uses the dictionary generated in the previous cell to create a new array that contains the same information as the previous x array, but this time the notes are represented by unique numbers instead of strings (“E4” for example). We have vectorized our data, so we now have lists of 32 numbers that will be used to predict the 33rd number that should follow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvE39aapX3RN"
      },
      "source": [
        "unique_y = list(set(y))\n",
        "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y))\n",
        "y_seq = np.array([y_note_to_int[i] for i in y])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQthEcFhNjAJ"
      },
      "source": [
        "Performs the vectorization of the y values, matching the process we used to vectorize the x values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzbArLxrZV-2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x_seq, y_seq, test_size = 0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC26EXu1kAtw"
      },
      "source": [
        "x_tr = np.array(x_tr)\n",
        "x_val = np.array(x_val)\n",
        "\n",
        "x_tr = np.expand_dims(x_tr, 1)\n",
        "x_val = np.expand_dims(x_val, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyCS66fZmlRc"
      },
      "source": [
        "x_tr = x_tr.astype(\"float32\")\n",
        "x_val = x_val.astype(\"float32\")\n",
        "y_tr = y_tr.astype(\"float32\")\n",
        "y_val = y_val.astype(\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8CwH2vwNmyA"
      },
      "source": [
        "Splits our data into train and validation sets. The following cell recasts our x arrays as numpy arrays and expands their dimensions, so they are the correct shape for the LSTM in our model. The final cell turns every value into a float (the model was picky about this). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB1PLzUHn3XK"
      },
      "source": [
        "x_tr.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7giWQxxYR8i"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "num_notes = len(frequent_notes)\n",
        "\n",
        "def lstm():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128, return_sequences=True))\n",
        "  model.add(LSTM(128))\n",
        "  model.add(Dense(256, activation=\"relu\"))\n",
        "  model.add(Dense(num_notes, activation=\"softmax\"))\n",
        "  model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTaE-vdwNtdH"
      },
      "source": [
        "Defines our basic LSTM model. It creates a variable equal to the number of possible outcomes for our model. It is a sequential model, with two LSTM layers stacked on top of each other. These are followed by a Dense layer, and then a final Dense layer of size “possible outcomes”. Our final Dense layer has activation “softmax”, so it will assign each possible outcome a probability between 0 and 1 that the next note/chord in the series will be that one. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpvpTC6DgewF"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "mc = ModelCheckpoint(\"best_model.h5\", monitop=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6lmQw5FhNWM"
      },
      "source": [
        "history = lstm().fit(x_tr, y_tr, batch_size=128, epochs=50, validation_data=(x_val, y_val), verbose=1, callbacks=[mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBknmYXnN-pl"
      },
      "source": [
        "Defines a callback that will be used to save the current version of the model during training only if it outperforms the previous best model. The following cell trains our model on the data we prepared. "
      ]
    }
  ]
}